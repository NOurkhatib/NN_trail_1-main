{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#Titanic-challenge-part-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import rcParams\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV, cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "%matplotlib inline\n",
    "rcParams['figure.figsize'] = 10,8\n",
    "sns.set(style='whitegrid', palette='muted',\n",
    "        rc={'figure.figsize': (15,10)})\n",
    "\n",
    "# Input data files are available in the \"../input/\" directory.\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n",
    "# print(os.listdir(\"../input\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir(\"./data/titanic-cleaned-data.csv\"))\n",
    "\n",
    "# Load data as Pandas dataframe\n",
    "train = pd.read_csv('./data/train_clean.csv', )\n",
    "test = pd.read_csv('./data/test_clean.csv')\n",
    "df = pd.concat([train, test], axis=0, sort=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_all(df):\n",
    "    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n",
    "        display(df)\n",
    "\n",
    "        \n",
    "display_all(df.describe(include='all').T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Survived'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"2.-Encode-categorical-variables\">2. Encode categorical variables<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#2.-Encode-categorical-variables\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h1>\n",
    "<p>We need to convert all categorical variables into numeric format. The categorical variables we will be keeping are <code>Embarked</code>, <code>Sex</code> and <code>Title</code>.</p>\n",
    "<p>The <code>Sex</code> variable can be encoded into single 1-or-0 column, but the other variables will need to be <a href=\"https://hackernoon.com/what-is-one-hot-encoding-why-and-when-do-you-have-to-use-it-e3c6186d008f\" rel=\" noreferrer nofollow\">one-hot encoded</a>. Regular label encoding assigns some category labels higher numerical values. This implies some sort of scale (Embarked = 1 is not <strong>more</strong> than Embarked = 0 - it's just <em>different</em>). One Hot Encoding avoids this problem.</p>\n",
    "<p>We will assume that there is some ordinality in the <code>Pclass</code> variable, so we will leave that as a single column.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Pclass', data=df, palette='hls', hue='Survived')\n",
    "# plt.figure(figsize=[1.4,1.4])\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Embarked', data=df, palette='hls', hue='Survived')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to category dtype\n",
    "df['Sex'] = df['Sex'].astype('category')\n",
    "\n",
    "\n",
    "# convert to category codes\n",
    "df['Sex'] = df['Sex'].cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# type(df['Sex'])\n",
    "# df['Sex']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset all categorical variables which need to be encoded\n",
    "categorical = ['Embarked', 'Title']\n",
    "\n",
    "for var in categorical:\n",
    "    df = pd.concat([df, \n",
    "                    pd.get_dummies(df[var], prefix=var)], axis=1)\n",
    "    del df[var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the variables we won't be using\n",
    "df.drop(['Cabin', 'Name', 'Ticket', 'PassengerId'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 id=\"3.-Random-Forest\">3. Random Forest<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.-Random-Forest\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h1>\n",
    "<p>Now, all that is left is to feed our data that has been cleaned, encoded and scaled to a random forest.<br>\n",
    "<a id=\"train-test\"></a></p>\n",
    "<h2 id=\"3.1.-Train/test-split\">3.1. Train/test split<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.1.-Train/test-split\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h2>\n",
    "<p>But first, we need to separate <em>data_df</em> back into <em>train</em> and <em>test</em> sets.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[pd.notnull(df['Survived'])]\n",
    "X_test = df[pd.isnull(df['Survived'])].drop(['Survived'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Validation-set\">Validation set<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#Validation-set\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3>\n",
    "<p>Since we can't use our test set to assess our model (it doesn't have any labels), we will create a separte 'validation set'. We will use this set to test how our model generalises to unseen data.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    train.drop(['Survived'], axis=1),\n",
    "    train['Survived'],\n",
    "    test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [X_train, X_val, X_test]:\n",
    "    # print(i.to_string)\n",
    "    print(i.shape)\n",
    "    # print(i.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Create-Random-Forest-model\">Create Random Forest model<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#Create-Random-Forest-model\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3>\n",
    "<p>We will first make a random forest model, using all of the default parameters.</p>\n",
    "<blockquote><p>Note: set the <code>random_state</code> to 42 for reproducibility</p>\n",
    "</blockquote>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"Train-model\">Train model<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#Train-model\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3>\n",
    "<p>Now, let's train the model on our training set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_val, rf.predict(X_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"3.2.-Cross-validation\">3.2. Cross-validation<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.2.-Cross-validation\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h2>\n",
    "<p>Keeping a separate validation set means that we have less data on which to train our model. Cross-validation allows us to train our model on <em>all</em> of the data, while still assessing its performance on unseen data.</p>\n",
    "<p>K-folds cross validation is the process of creating <em>k</em> different train/validate splits in the data and training the model <em>k</em> times.</p>\n",
    "<p><img src=\"https://upload.wikimedia.org/wikipedia/commons/1/1c/K-fold_cross_validation_EN.jpg\" alt=\"CV\"></p>\n",
    "<p>In the image above, k=4. This means that the model will be trained 4 times, each time using 1/4 of the data for validation. In this way, each of the four 'folds' takes one turn sitting out from training and is used as the validation set.</p>\n",
    "<p>Let's combine our train and validation sets back into one training set, and then use cross-validation to assess our model:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, X_val])\n",
    "y_train = pd.concat([y_train, y_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Now we have all of training data again. Let's fit a model to it, and assess its accuracy using 5-fold cross-validation:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "cross_val_score(rf, X_train, y_train, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_val_score(rf, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Here, our CV score is slightly lower than our previous single validation score. Taking a look at the scores for each of the folds, the score does seem to vary slightly.</p>\n",
    "<p>Cross-validation has the added advantage of being a more robust measure of model accuracy than single validation.</p>\n",
    "<blockquote><p>Note: the method we used initially is actually just 1-fold cross-validation</p>\n",
    "</blockquote>\n",
    "\n",
    "<h2 id=\"3.3.-Hyperparameter-tuning\">3.3. Hyperparameter tuning<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.3.-Hyperparameter-tuning\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h2>\n",
    "<p>Our first model didn't do too badly! It scored over 80% on the CV score. However, we didn't put any thought into our choice of hyperparameters, we simply went with the defaults.</p>\n",
    "<p>Take a look at the various parameters by using the <code>help()</code> function:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(RandomForestClassifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>It is hard to know the best values for each of these hyperparameters without first <em>trying</em> them out. If we wanted to know the best value for the <code>n_estimators</code> parameter, we could fit a few models, each with a different value, and see which one tests the best.</p>\n",
    "<p><strong>Grid search</strong> allows us to do this for multiple parameters simultaneously. We will select a few different parameters that we want to tune, and for each one we will provide a few different values to try out. Then grid search will fit models to every possible combination of these parameter values and use <strong>cross-validation</strong> to assess the performance in each case.</p>\n",
    "<p>Furthermore, since we are using CV, we don't need to keep a separate validation set.</p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"text_cell_render border-box-sizing rendered_html\">\n",
    "<h3 id=\"3.2.1.-Number-of-estimators-and-max-depth\">3.2.1. Number of estimators and max depth<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.2.1.-Number-of-estimators-and-max-depth\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3><p>We will start by tuning the <code>n_estimators</code> (number of trees in the forest) and the <code>max_depth</code> (how deep each tree grows) parameters.</p>\n",
    "<p>The first step that we need to do is to define the grid of parameters over which to search:</p>\n",
    "\n",
    "</div>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [10, 100, 1000, 2000]\n",
    "max_depth = [None, 5, 10, 20]\n",
    "param_grid = dict(n_estimators=n_estimators, max_depth=max_depth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>We have set out a total of <span class=\"MathJax_Preview\" style=\"color: inherit; display: none;\"></span><span class=\"MathJax\" id=\"MathJax-Element-1-Frame\" tabindex=\"0\" data-mathml=\"<math xmlns=&quot;http://www.w3.org/1998/Math/MathML&quot;><mn>4</mn><mo>&amp;#x00D7;</mo><mn>4</mn><mo>=</mo><mn>16</mn></math>\" role=\"presentation\" style=\"position: relative;\"><nobr aria-hidden=\"true\"><span class=\"math\" id=\"MathJax-Span-1\" style=\"width: 5.598em; display: inline-block;\"><span style=\"display: inline-block; position: relative; width: 4.646em; height: 0px; font-size: 120%;\"><span style=\"position: absolute; clip: rect(1.432em, 1004.59em, 2.443em, -999.997em); top: -2.259em; left: 0em;\"><span class=\"mrow\" id=\"MathJax-Span-2\"><span class=\"mn\" id=\"MathJax-Span-3\" style=\"font-family: MathJax_Main;\">4</span><span class=\"mo\" id=\"MathJax-Span-4\" style=\"font-family: MathJax_Main; padding-left: 0.241em;\">×</span><span class=\"mn\" id=\"MathJax-Span-5\" style=\"font-family: MathJax_Main; padding-left: 0.241em;\">4</span><span class=\"mo\" id=\"MathJax-Span-6\" style=\"font-family: MathJax_Main; padding-left: 0.301em;\">=</span><span class=\"mn\" id=\"MathJax-Span-7\" style=\"font-family: MathJax_Main; padding-left: 0.301em;\">16</span></span><span style=\"display: inline-block; width: 0px; height: 2.265em;\"></span></span></span><span style=\"display: inline-block; overflow: hidden; vertical-align: -0.068em; border-left: 0px solid; width: 0px; height: 1.004em;\"></span></span></nobr><span class=\"MJX_Assistive_MathML\" role=\"presentation\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><mn>4</mn><mo>×</mo><mn>4</mn><mo>=</mo><mn>16</mn></math></span></span><script type=\"math/tex\" id=\"MathJax-Element-1\">4 \\times 4 = 16</script> models over which to search. Grid search uses cross-validation on each of the models, so if we use 3-folds cross-validation, that will leave us with 48 different fits to try out. (You can see how the number of fits can grow pretty quickly as we increase the number of parameters!)</p>\n",
    "\n",
    "<p>The good news is that SkLearn's grid search allows us to run the job in parallel. Including the <code>n_jobs=-1</code> argument below let's grid search run on all of the available cores on the host machine.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the default model\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=rf, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
    "</pre>\n",
    "<pre>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   21.6s\n",
    "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   31.0s finished\n",
    "</pre>\n",
    "<p>Now let's take a look at the results of the grid search.</p>\n",
    "<p>We can get the best performing model directly from <code>grid_result</code>:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_estimator_\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
    "            max_depth=5, max_features='auto', max_leaf_nodes=None,\n",
    "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
    "            min_samples_leaf=1, min_samples_split=2,\n",
    "            min_weight_fraction_leaf=0.0, n_estimators=2000, n_jobs=None,\n",
    "            oob_score=False, random_state=42, verbose=0, warm_start=False)</pre>\n",
    "  <p>Or just the best parameters:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>But let's take a look at all of the models so we can make a more informed decision</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"3.2.2.-Leaf-size\">3.2.2. Leaf size<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.2.2.-Leaf-size\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3>\n",
    "<p>The <code>min_samples_leaf</code> argument controls the size of the leaves in the trees.</p>\n",
    "<p>We will set out the grid in a similar manner as before, only this time we will use the <code>max_depth</code> and <code>n_estimators</code> parameters that we found above.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid\n",
    "max_features = [5, 8, 10, 12, None]\n",
    "bootstrap = [True, False]\n",
    "param_grid = dict(max_features=max_features, bootstrap=bootstrap)\n",
    "\n",
    "# create the model with new leaf size\n",
    "rf = grid_result.best_estimator_\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=rf, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<pre>Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
    "</pre>\n",
    "<pre>[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
    "[Parallel(n_jobs=-1)]: Done  18 out of  18 | elapsed:   19.0s finished\n",
    "</pre>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 id=\"3.2.3.-To-bag-or-not-to-bag\">3.2.3. To bag or not to bag<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#3.2.3.-To-bag-or-not-to-bag\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h3>\n",
    "<p>Bootstrap aggregating (or bagging) is a special case of the random forest where we bootstrap (sample with replacement) from the n training obersvations to create a new training set of size n for each tree. Furthermore, each tree considers all variables when making each split.</p>\n",
    "\n",
    "<p>We can use grid search to determine if bootstrapping will be an appropriate method to use.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the grid\n",
    "max_features = [5, 8, 10, 12, None]\n",
    "bootstrap = [True, False]\n",
    "param_grid = dict(max_features=max_features, bootstrap=bootstrap)\n",
    "\n",
    "# create the model with new leaf size\n",
    "rf = grid_result.best_estimator_\n",
    "\n",
    "# search the grid\n",
    "grid = GridSearchCV(estimator=rf, \n",
    "                    param_grid=param_grid,\n",
    "                    cv=3,\n",
    "                    verbose=2,\n",
    "                    n_jobs=-1)\n",
    "\n",
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"4.-Make-Predictions-on-Test-Set\">4. Make Predictions on Test Set<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#4.-Make-Predictions-on-Test-Set\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h2>\n",
    "<p>Finally, we can attempt to predict which passengers in the test set survived.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = grid_result.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test our CV score\n",
    "cross_val_score(rf, X_train, y_train, cv=5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['Survived'] = rf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution = test[['PassengerId', 'Survived']]\n",
    "solution['Survived'] = solution['Survived'].apply(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Output-Final-Predictions\">Output Final Predictions<a class=\"anchor-link\" href=\"https://www.kaggle.com/code/jamesleslie/titanic-random-forest-grid-search/notebook#Output-Final-Predictions\" target=\"_self\" rel=\" noreferrer nofollow\">¶</a></h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solution.to_csv(\"Random_Forest_Solution.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
